{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 10170004,
     "sourceType": "datasetVersion",
     "datasetId": 6275166
    },
    {
     "sourceId": 10183488,
     "sourceType": "datasetVersion",
     "datasetId": 6290858
    },
    {
     "sourceId": 198188,
     "sourceType": "modelInstanceVersion",
     "isSourceIdPinned": true,
     "modelInstanceId": 169033,
     "modelId": 191384
    },
    {
     "sourceId": 198191,
     "sourceType": "modelInstanceVersion",
     "isSourceIdPinned": true,
     "modelInstanceId": 169036,
     "modelId": 191387
    }
   ],
   "dockerImageVersionId": 30805,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "import cv2\nimport mediapipe as mp\nimport numpy as np\nimport matplotlib.pyplot as plt",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-14T15:37:09.038599Z",
     "iopub.execute_input": "2024-12-14T15:37:09.038880Z",
     "iopub.status.idle": "2024-12-14T15:37:20.441321Z",
     "shell.execute_reply.started": "2024-12-14T15:37:09.038854Z",
     "shell.execute_reply": "2024-12-14T15:37:20.440400Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Initialize MediaPipe Pose\nmp_pose = mp.solutions.pose\nmp_drawing = mp.solutions.drawing_utils\npose = mp_pose.Pose()\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-14T14:22:44.072956Z",
     "iopub.execute_input": "2024-12-14T14:22:44.073418Z",
     "iopub.status.idle": "2024-12-14T14:22:44.091735Z",
     "shell.execute_reply.started": "2024-12-14T14:22:44.073390Z",
     "shell.execute_reply": "2024-12-14T14:22:44.086307Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Function to calculate angle between three points\ndef calculate_angle(a, b, c):\n    a = np.array(a)  # First point\n    b = np.array(b)  # Midpoint\n    c = np.array(c)  # Last point\n    \n    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n    angle = np.abs(radians * 180.0 / np.pi)\n    \n    if angle > 180.0:\n        angle = 360 - angle\n        \n    return angle",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-14T14:22:44.096046Z",
     "iopub.execute_input": "2024-12-14T14:22:44.097244Z",
     "iopub.status.idle": "2024-12-14T14:22:44.128025Z",
     "shell.execute_reply.started": "2024-12-14T14:22:44.097201Z",
     "shell.execute_reply": "2024-12-14T14:22:44.126803Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Load an example image\nimage_path = \"/kaggle/input/82yogaclasses/yoga_images/images/Tree_Pose_or_Vrksasana_/0_42.jpg\"  # Update with a valid path\nimage = cv2.imread(image_path)\nimage_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-14T14:22:44.129476Z",
     "iopub.execute_input": "2024-12-14T14:22:44.129948Z",
     "iopub.status.idle": "2024-12-14T14:22:44.195048Z",
     "shell.execute_reply.started": "2024-12-14T14:22:44.129898Z",
     "shell.execute_reply": "2024-12-14T14:22:44.193917Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Process the image with MediaPipe\nresults = pose.process(image_rgb)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-14T14:22:44.196144Z",
     "iopub.execute_input": "2024-12-14T14:22:44.196525Z",
     "iopub.status.idle": "2024-12-14T14:22:44.306382Z",
     "shell.execute_reply.started": "2024-12-14T14:22:44.196479Z",
     "shell.execute_reply": "2024-12-14T14:22:44.305208Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Extract landmarks\nangle = None  # Initialize the variable to avoid NameError\n\nif results.pose_landmarks:\n    landmarks = results.pose_landmarks.landmark\n\n    # Get coordinates for keypoints (example: left shoulder, elbow, and wrist)\n    left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, \n                     landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n    left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, \n                  landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n    left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, \n                  landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n\n    # Calculate angle\n    angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n    print(f\"Left Arm Angle: {angle}\")\n\n    # Visualize keypoints and skeleton\n    annotated_image = image.copy()\n    mp_drawing.draw_landmarks(annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n    \n    # Display image\n    plt.figure(figsize=(10, 10))\n    plt.imshow(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))\n    plt.axis('off')\n    plt.show()\nelse:\n    print(\"No landmarks detected. Please ensure the input image shows a person performing a yoga pose.\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-14T14:22:44.307850Z",
     "iopub.execute_input": "2024-12-14T14:22:44.308227Z",
     "iopub.status.idle": "2024-12-14T14:22:44.657398Z",
     "shell.execute_reply.started": "2024-12-14T14:22:44.308180Z",
     "shell.execute_reply": "2024-12-14T14:22:44.656562Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Provide feedback only if angle is calculated\nif angle is not None:\n    if angle < 170:\n        print(\"Straighten your arm for better alignment.\")\n        feedback = \"Straighten your arm for better alignment.\"\n    else:\n        print(\"Great job maintaining arm alignment!\")\n        feedback = \"Great job maintaining arm alignment.\"\nelse:\n    feedback = \"No landmarks detected. Unable to provide feedback.\"\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-14T14:22:44.658645Z",
     "iopub.execute_input": "2024-12-14T14:22:44.659037Z",
     "iopub.status.idle": "2024-12-14T14:22:44.664928Z",
     "shell.execute_reply.started": "2024-12-14T14:22:44.658998Z",
     "shell.execute_reply": "2024-12-14T14:22:44.663966Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Store session insights\nimport json\nsession_data = {\n    \"pose\": \"Tree Pose\",\n    \"angles\": {\"left_arm\": angle if angle is not None else \"Not detected\"},\n    \"feedback\": feedback,\n    \"time_spent\": \"15 seconds\"\n}",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-14T14:22:44.666102Z",
     "iopub.execute_input": "2024-12-14T14:22:44.666553Z",
     "iopub.status.idle": "2024-12-14T14:22:44.682665Z",
     "shell.execute_reply.started": "2024-12-14T14:22:44.666515Z",
     "shell.execute_reply": "2024-12-14T14:22:44.682005Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Save insights to a file\nwith open(\"session_insights.json\", \"w\") as file:\n    json.dump(session_data, file, indent=4)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-14T14:22:44.685055Z",
     "iopub.execute_input": "2024-12-14T14:22:44.685380Z",
     "iopub.status.idle": "2024-12-14T14:22:44.693582Z",
     "shell.execute_reply.started": "2024-12-14T14:22:44.685355Z",
     "shell.execute_reply": "2024-12-14T14:22:44.692711Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# trial",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import cv2\nimport mediapipe as mp\nimport numpy as np\nimport os\nimport json\nfrom tqdm import tqdm\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-14T14:22:44.694765Z",
     "iopub.execute_input": "2024-12-14T14:22:44.695071Z",
     "iopub.status.idle": "2024-12-14T14:22:44.708094Z",
     "shell.execute_reply.started": "2024-12-14T14:22:44.695046Z",
     "shell.execute_reply": "2024-12-14T14:22:44.707248Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Initialize MediaPipe Pose\nmp_pose = mp.solutions.pose\nmp_drawing = mp.solutions.drawing_utils\n\n# Define function to extract keypoints\ndef extract_keypoints(image_path):\n    with mp_pose.Pose(static_image_mode=True) as pose:\n        image = cv2.imread(image_path)\n        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        results = pose.process(image_rgb)\n        \n        if results.pose_landmarks:\n            # Flatten landmarks into a single array\n            keypoints = np.array([[lm.x, lm.y, lm.z] for lm in results.pose_landmarks.landmark]).flatten()\n            return keypoints\n        else:\n            return None\n\n\n\n",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "def process_dataset(dataset_path, output_file):\n    data = {}  # Initialize a dictionary to hold the processed data\n    classes = os.listdir(dataset_path)\n    \n    valid_extensions = [\".jpg\", \".jpeg\", \".png\"]\n    \n    for class_name in tqdm(classes, desc=\"Processing classes\"):\n        class_path = os.path.join(dataset_path, class_name)\n        if not os.path.isdir(class_path):\n            continue\n        \n        # Initialize an empty list for the class if not already done\n        if class_name not in data:\n            data[class_name] = []\n        \n        for img_name in os.listdir(class_path):\n            if not any(img_name.lower().endswith(ext) for ext in valid_extensions):\n                print(f\"Skipping non-image file: {img_name}\")\n                continue\n            \n            img_path = os.path.join(class_path, img_name)\n            \n            # Debugging: Check if file exists\n            if not os.path.exists(img_path):\n                print(f\"File not found: {img_path}\")\n                continue\n            \n            # Debugging: Print file path\n            print(f\"Processing: {img_path}\")\n            \n            # Attempt to read the image\n            image = cv2.imread(img_path)\n            if image is None:\n                print(f\"Failed to read image: {img_path}\")\n                continue\n            \n            keypoints = extract_keypoints(img_path)\n            if keypoints is not None:\n                data[class_name].append({\"image\": img_name, \"keypoints\": keypoints.tolist()})\n    \n    # Save keypoints to JSON\n    with open(output_file, \"w\") as file:\n        json.dump(data, file, indent=4)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-14T14:17:38.868342Z",
     "iopub.execute_input": "2024-12-14T14:17:38.868688Z",
     "iopub.status.idle": "2024-12-14T14:17:38.879622Z",
     "shell.execute_reply.started": "2024-12-14T14:17:38.868644Z",
     "shell.execute_reply": "2024-12-14T14:17:38.878803Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import warnings\n\n# Suppress MediaPipe specific warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*feedback manager requires.*\")\n",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Run the processing\ndataset_path = \"/kaggle/input/82yogaclasses/yoga_images/images\"  # Change to your dataset path\noutput_file = \"keypoints.json\"\nprocess_dataset(dataset_path, output_file)",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nimport tensorflow as tf\nimport json\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Input, GlobalAveragePooling2D, Conv2D, MaxPooling2D, Flatten\nfrom tensorflow.keras.applications import MobileNetV2, EfficientNetB0, ResNet50\nimport gc\nfrom tensorflow.keras.backend import clear_session",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-14T15:37:22.675885Z",
     "iopub.execute_input": "2024-12-14T15:37:22.676233Z",
     "iopub.status.idle": "2024-12-14T15:37:22.681296Z",
     "shell.execute_reply.started": "2024-12-14T15:37:22.676194Z",
     "shell.execute_reply": "2024-12-14T15:37:22.680463Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Load keypoints data\nwith open(\"/kaggle/input/keypoints/keypoints (1).json\", \"r\") as file:\n    keypoint_data = json.load(file)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-14T15:37:22.695268Z",
     "iopub.execute_input": "2024-12-14T15:37:22.695531Z",
     "iopub.status.idle": "2024-12-14T15:37:23.424555Z",
     "shell.execute_reply.started": "2024-12-14T15:37:22.695508Z",
     "shell.execute_reply": "2024-12-14T15:37:23.423851Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Prepare feature matrix and labels\nX = []  # Features\ny = []  # Labels",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-14T15:37:23.426590Z",
     "iopub.execute_input": "2024-12-14T15:37:23.426852Z",
     "iopub.status.idle": "2024-12-14T15:37:23.430838Z",
     "shell.execute_reply.started": "2024-12-14T15:37:23.426826Z",
     "shell.execute_reply": "2024-12-14T15:37:23.429961Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "for class_name, samples in keypoint_data.items():\n    for sample in samples:\n        X.append(sample[\"keypoints\"])\n        y.append(class_name)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-14T15:37:23.431972Z",
     "iopub.execute_input": "2024-12-14T15:37:23.432238Z",
     "iopub.status.idle": "2024-12-14T15:37:23.444863Z",
     "shell.execute_reply.started": "2024-12-14T15:37:23.432215Z",
     "shell.execute_reply": "2024-12-14T15:37:23.444049Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "\n# Encode labels\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-14T15:37:23.445841Z",
     "iopub.execute_input": "2024-12-14T15:37:23.446129Z",
     "iopub.status.idle": "2024-12-14T15:37:23.472710Z",
     "shell.execute_reply.started": "2024-12-14T15:37:23.446105Z",
     "shell.execute_reply": "2024-12-14T15:37:23.471911Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-14T15:37:23.473539Z",
     "iopub.execute_input": "2024-12-14T15:37:23.473764Z",
     "iopub.status.idle": "2024-12-14T15:37:23.488409Z",
     "shell.execute_reply.started": "2024-12-14T15:37:23.473740Z",
     "shell.execute_reply": "2024-12-14T15:37:23.487850Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Convert to numpy arrays\nX_train, X_test = np.array(X_train), np.array(X_test)\ny_train, y_test = np.array(y_train), np.array(y_test)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-14T15:37:23.489281Z",
     "iopub.execute_input": "2024-12-14T15:37:23.489512Z",
     "iopub.status.idle": "2024-12-14T15:37:23.570881Z",
     "shell.execute_reply.started": "2024-12-14T15:37:23.489489Z",
     "shell.execute_reply": "2024-12-14T15:37:23.570061Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Data generator\ndef data_generator(X, y, batch_size=16):\n    while True:\n        indices = np.random.permutation(len(X))\n        for i in range(0, len(X), batch_size):\n            batch_indices = indices[i:i + batch_size]\n            batch_X = np.array([np.resize(X[j], (128, 128, 3)) for j in batch_indices])\n            batch_y = y[batch_indices]\n            yield batch_X, batch_y\n\ntrain_gen = data_generator(X_train, y_train, batch_size=16)\nval_gen = data_generator(X_test, y_test, batch_size=16)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-12T18:12:52.485847Z",
     "iopub.execute_input": "2024-12-12T18:12:52.486715Z",
     "iopub.status.idle": "2024-12-12T18:12:52.492165Z",
     "shell.execute_reply.started": "2024-12-12T18:12:52.486684Z",
     "shell.execute_reply": "2024-12-12T18:12:52.491211Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Define models to compare\ndef build_mlp(input_shape, num_classes):\n    model = Sequential([\n        Dense(128, activation=\"relu\", input_shape=(input_shape,)),\n        Dropout(0.2),\n        Dense(num_classes, activation=\"softmax\")\n    ])\n    return model",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-12T18:12:52.841481Z",
     "iopub.execute_input": "2024-12-12T18:12:52.841796Z",
     "iopub.status.idle": "2024-12-12T18:12:52.846494Z",
     "shell.execute_reply.started": "2024-12-12T18:12:52.841771Z",
     "shell.execute_reply": "2024-12-12T18:12:52.845510Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "def build_cnn(input_shape, num_classes):\n    model = Sequential([\n        Conv2D(32, (3, 3), activation=\"relu\", input_shape=input_shape),\n        MaxPooling2D((2, 2)),\n        Dropout(0.2),\n        Flatten(),\n        Dense(128, activation=\"relu\"),\n        Dense(num_classes, activation=\"softmax\")\n    ])\n    return model",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-12T18:12:53.136268Z",
     "iopub.execute_input": "2024-12-12T18:12:53.136642Z",
     "iopub.status.idle": "2024-12-12T18:12:53.142033Z",
     "shell.execute_reply.started": "2024-12-12T18:12:53.136608Z",
     "shell.execute_reply": "2024-12-12T18:12:53.140932Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "def build_mobilenet(input_shape, num_classes):\n    base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n    base_model.trainable = False\n    inputs = Input(shape=input_shape)\n    x = base_model(inputs, training=False)\n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(0.2)(x)\n    outputs = Dense(num_classes, activation=\"softmax\")(x)\n    model = Model(inputs, outputs)\n    return model",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-12T18:12:53.378246Z",
     "iopub.execute_input": "2024-12-12T18:12:53.378560Z",
     "iopub.status.idle": "2024-12-12T18:12:53.383617Z",
     "shell.execute_reply.started": "2024-12-12T18:12:53.378529Z",
     "shell.execute_reply": "2024-12-12T18:12:53.382760Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "def build_efficientnet(input_shape, num_classes):\n    base_model = EfficientNetB0(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n    base_model.trainable = False\n    inputs = Input(shape=input_shape)\n    x = base_model(inputs, training=False)\n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(0.2)(x)\n    outputs = Dense(num_classes, activation=\"softmax\")(x)\n    model = Model(inputs, outputs)\n    return model",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-12T18:12:53.675531Z",
     "iopub.execute_input": "2024-12-12T18:12:53.676313Z",
     "iopub.status.idle": "2024-12-12T18:12:53.681287Z",
     "shell.execute_reply.started": "2024-12-12T18:12:53.676280Z",
     "shell.execute_reply": "2024-12-12T18:12:53.680299Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "def build_resnet(input_shape, num_classes):\n    base_model = ResNet50(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n    base_model.trainable = False\n    inputs = Input(shape=input_shape)\n    x = base_model(inputs, training=False)\n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(0.2)(x)\n    outputs = Dense(num_classes, activation=\"softmax\")(x)\n    model = Model(inputs, outputs)\n    return model",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-12T18:12:53.986043Z",
     "iopub.execute_input": "2024-12-12T18:12:53.986405Z",
     "iopub.status.idle": "2024-12-12T18:12:53.991856Z",
     "shell.execute_reply.started": "2024-12-12T18:12:53.986357Z",
     "shell.execute_reply": "2024-12-12T18:12:53.990930Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "models = {\n    \"MLP\": build_mlp(len(X_train[0]), len(label_encoder.classes_)),\n    \"CNN\": build_cnn((128, 128, 3), len(label_encoder.classes_)),\n    \"MobileNetV2\": build_mobilenet((128, 128, 3), len(label_encoder.classes_)),\n    \"EfficientNet\": build_efficientnet((128, 128, 3), len(label_encoder.classes_)),\n    \"ResNet50\": build_resnet((128, 128, 3), len(label_encoder.classes_))\n}\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-12T18:12:54.629646Z",
     "iopub.execute_input": "2024-12-12T18:12:54.630471Z",
     "iopub.status.idle": "2024-12-12T18:12:58.526526Z",
     "shell.execute_reply.started": "2024-12-12T18:12:54.630433Z",
     "shell.execute_reply": "2024-12-12T18:12:58.525470Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "X_train_resized = np.array([np.resize(x, (128, 128, 3)) for x in X_train])\nX_test_resized = np.array([np.resize(x, (128, 128, 3)) for x in X_test])\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-12T18:12:58.535564Z",
     "iopub.execute_input": "2024-12-12T18:12:58.535892Z",
     "iopub.status.idle": "2024-12-12T18:13:07.109232Z",
     "shell.execute_reply.started": "2024-12-12T18:12:58.535840Z",
     "shell.execute_reply": "2024-12-12T18:13:07.108189Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Train and evaluate models\nbest_model = None\nbest_model_name = \"\"\nbest_accuracy = 0\nresults = {}\nmodel_histories = {}",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-12T18:13:07.111398Z",
     "iopub.execute_input": "2024-12-12T18:13:07.111690Z",
     "iopub.status.idle": "2024-12-12T18:13:07.116214Z",
     "shell.execute_reply.started": "2024-12-12T18:13:07.111662Z",
     "shell.execute_reply": "2024-12-12T18:13:07.115340Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "for model_name, model in models.items():\n    print(f\"Training {model_name}...\")\n\n    reset_memory()  # Clear memory before training\n\n    if model_name == \"MLP\":\n        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n                      loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n        history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=16, verbose=1)\n    else:\n        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n                      loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n        history = model.fit(train_gen, steps_per_epoch=len(X_train) // 16,\n                            validation_data=val_gen, validation_steps=len(X_test) // 16, epochs=50, verbose=1)\n\n    # Store training history\n    model_histories[model_name] = history\n\n    # Evaluate the model\n    if model_name == \"MLP\":\n        y_pred = model.predict(X_test)\n    else:\n        y_pred = model.predict(np.array([np.resize(x, (128, 128, 3)) for x in X_test]))\n\n    y_pred_classes = np.argmax(y_pred, axis=1)\n    accuracy = accuracy_score(y_test, y_pred_classes)\n    results[model_name] = accuracy\n\n    print(f\"{model_name} Accuracy: {accuracy}\")\n\n    # Check if this model is the best\n    if accuracy > best_accuracy:\n        best_accuracy = accuracy\n        best_model = model\n        best_model_name = model_name",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-12T18:13:07.117373Z",
     "iopub.execute_input": "2024-12-12T18:13:07.117735Z",
     "iopub.status.idle": "2024-12-12T18:53:45.609427Z",
     "shell.execute_reply.started": "2024-12-12T18:13:07.117695Z",
     "shell.execute_reply": "2024-12-12T18:53:45.608437Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Fine-tune the best model (if it is a pre-trained model)\nif isinstance(best_model, Model):\n    print(f\"Fine-tuning the best model ({best_model.name})...\")\n    best_model.layers[0].trainable = True  # Unfreeze the base model layers\n    best_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), \n                       loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n    best_model.fit(X_train_resized, y_train, validation_data=(X_test_resized, y_test), epochs=10, batch_size=32, verbose=1)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-12T18:54:22.979835Z",
     "iopub.execute_input": "2024-12-12T18:54:22.980634Z",
     "iopub.status.idle": "2024-12-12T18:54:29.699334Z",
     "shell.execute_reply.started": "2024-12-12T18:54:22.980599Z",
     "shell.execute_reply": "2024-12-12T18:54:29.698072Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Save the best model\nbest_model.save(\"best_pose_detection_model.h5\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-12T18:54:33.508462Z",
     "iopub.execute_input": "2024-12-12T18:54:33.509254Z",
     "iopub.status.idle": "2024-12-12T18:54:33.528069Z",
     "shell.execute_reply.started": "2024-12-12T18:54:33.509219Z",
     "shell.execute_reply": "2024-12-12T18:54:33.527193Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Print results\nprint(\"Model Comparison Results:\")\nfor model_name, accuracy in results.items():\n    print(f\"{model_name}: {accuracy:.4f}\")\n\nprint(f\"\\nBest Model: {best_model_name} with Accuracy: {best_accuracy:.4f}\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-12T18:54:34.788658Z",
     "iopub.execute_input": "2024-12-12T18:54:34.789574Z",
     "iopub.status.idle": "2024-12-12T18:54:34.794639Z",
     "shell.execute_reply.started": "2024-12-12T18:54:34.789538Z",
     "shell.execute_reply": "2024-12-12T18:54:34.793583Z"
    }
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
